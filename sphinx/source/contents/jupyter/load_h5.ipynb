{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load datasets stored in .h5 file format\n",
    "=======================================\n",
    "\n",
    "This example demonstrates how to load the data from a stored .h5 file and to build a \n",
    "data generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we create a small temporary dataset by utilizing dataset1, compounding 5 source cases and the CSM as input feature.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from acoupipe import Dataset1\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # change tensorflow log level for doc purposes\n",
    "\n",
    "# training dataset\n",
    "d1 = Dataset1(\n",
    "        split=\"training\",\n",
    "        size=5,\n",
    "        features=[\"csm\"])\n",
    "\n",
    "# save to .h5 file\n",
    "d1.save_h5(name=\"/tmp/dataset.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AcouPipe toolbox provides the `LoadH5Dataset` class to load the datasets stored into HDF5 format.\n",
    "One can access each individual sample/source case by the h5f attribute of the class. To extract the first input feature ('csm' in this case) of the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acoupipe import LoadH5Dataset\n",
    "\n",
    "dataset_h5 = LoadH5Dataset(name=\"/tmp/dataset.h5\")\n",
    "\n",
    "s1 = dataset_h5.h5f['1']['csm'][:] # we use [:] to copy the data from file into the variable s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a TensorFlow/Keras Dataset \n",
    "\n",
    "With these definitions, a Python generator can be created which can be consumed by the Tensorflow Dataset API. Here, the dataset comprises the location, squared sound pressure, and the CSM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.07077019 -0.04793944  0.31192958  0.138183  ]\n",
      " [ 0.03267673  0.07899582 -0.09707411  0.26443505]\n",
      " [ 0.5         0.5         0.5         0.5       ]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_generator = dataset_h5.get_dataset_generator(\n",
    "            features=['loc','p2','csm'], # the desired features to return from the file\n",
    "            )\n",
    "\n",
    "# provide the signature of the features\n",
    "output_signature = {\n",
    "            'loc' : tf.TensorSpec(shape=(3,None), dtype=tf.float32),\n",
    "            'p2' : tf.TensorSpec(shape=(None,None), dtype=tf.float32),\n",
    "            'csm':  tf.TensorSpec(shape=(None,64,64,None), dtype=tf.float32),\n",
    "            }\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "            generator=data_generator,\n",
    "            output_signature=output_signature\n",
    "            )\n",
    "\n",
    "data = next(iter(dataset))\n",
    "print(data['loc'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b84133aa5d27198834684dc5cf37286f31547fcb562f18c04d9e25d99e7281e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
