{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load datasets stored in .h5 file format\n",
    "=======================================\n",
    "\n",
    "This example demonstrates how to load the data from a stored .h5 file and to build a \n",
    "data generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we create a small temporary dataset by utilizing dataset1, compounding 5 source cases and the CSM as input feature.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;31;119;180m██████████\u001b[0m| 5/5 [00:03<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from acoupipe.datasets.dataset1 import Dataset1\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # change tensorflow log level for doc purposes\n",
    "\n",
    "# training dataset\n",
    "d1 = Dataset1(features=[\"csm\"])\n",
    "\n",
    "# save to .h5 file\n",
    "d1.save_h5(split=\"training\", size=5, name=\"/tmp/dataset.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AcouPipe toolbox provides the `LoadH5Dataset` class to load the datasets stored into HDF5 format.\n",
    "One can access each individual sample/source case by the h5f attribute of the class. To extract the first input feature ('csm' in this case) of the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception occurred in traits notification handler for object: <acoupipe.loader.LoadH5Dataset object at 0x7f557c6e7c70>, trait: basename, old value: None, new value: dataset\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kujawski/mambaforge/envs/py39/lib/python3.9/site-packages/traits/trait_notifiers.py\", line 524, in _dispatch_change_event\n",
      "    self.dispatch(handler, *args)\n",
      "  File \"/home/kujawski/mambaforge/envs/py39/lib/python3.9/site-packages/traits/trait_notifiers.py\", line 486, in dispatch\n",
      "    handler(*args)\n",
      "  File \"/home/kujawski/mambaforge/envs/py39/lib/python3.9/site-packages/acoupipe/loader.py\", line 95, in load_data\n",
      "    self.load_metadata()\n",
      "  File \"/home/kujawski/mambaforge/envs/py39/lib/python3.9/site-packages/acoupipe/loader.py\", line 105, in load_metadata\n",
      "    int_indices = list(map(int,indices))\n",
      "ValueError: invalid literal for int() with base 10: '<HDF5 group \"'\n"
     ]
    }
   ],
   "source": [
    "from acoupipe.loader import LoadH5Dataset\n",
    "\n",
    "dataset_h5 = LoadH5Dataset(name=\"/tmp/dataset.h5\")\n",
    "\n",
    "s1 = dataset_h5.h5f['1']['csm'][:] # we use [:] to copy the data from file into the variable s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['1', '2', '3', '4', '5', '<HDF5 group \"', 'metadata']>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_h5.h5f.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a TensorFlow/Keras Dataset \n",
    "\n",
    "With these definitions, a Python generator can be created which can be consumed by the Tensorflow Dataset API. Here, the dataset comprises the location, squared sound pressure, and the CSM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_generator = dataset_h5.get_dataset_generator(\n",
    "            features=['loc','p2','csm'], # the desired features to return from the file\n",
    "            )\n",
    "\n",
    "# provide the signature of the features\n",
    "output_signature = {\n",
    "            'loc' : tf.TensorSpec(shape=(3,None), dtype=tf.float32),\n",
    "            'p2' : tf.TensorSpec(shape=(None,None), dtype=tf.float32),\n",
    "            'csm':  tf.TensorSpec(shape=(None,64,64,None), dtype=tf.float32),\n",
    "            }\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "            generator=data_generator,\n",
    "            output_signature=output_signature\n",
    "            )\n",
    "\n",
    "data = next(iter(dataset))\n",
    "print(data['loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b84133aa5d27198834684dc5cf37286f31547fcb562f18c04d9e25d99e7281e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
